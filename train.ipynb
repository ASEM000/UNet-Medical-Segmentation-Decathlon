{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96471453-6be9-4c8c-b356-fb2db10af183",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "764a5103-6ba4-4672-aea5-343f83a77456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from typing import List,Tuple,Callable,Dict\n",
    "\n",
    "from utility_functions import *\n",
    "from dataset_dataloader import *\n",
    "from variable_unet import *\n",
    "from augmentation_class import *\n",
    "from train_utility_functions import *\n",
    "\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09989d4c-6c42-4096-be93-d3d29ec2242e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a92fced3-49f6-4ffc-94b5-5ac50cc533f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "# Configurations\n",
    "name = 'basline_sift'\n",
    "args = {\n",
    "    'root' : '',\n",
    "    'samples':1,\n",
    "    'log_root' : 'log',\n",
    "    'ckpt_root' : 'checkpoints',\n",
    "    'sift' : True,\n",
    "    'batch_size' : 16,\n",
    "    'crop_size' : 256,\n",
    "    'epochs' : 100,\n",
    "    'lr' : 1e-2,\n",
    "    'device' : 'cuda:0',\n",
    "\n",
    "    # U-Net configs\n",
    "    'init_filters': 4,\n",
    "    'block_count': 7,\n",
    "    'upsample': False,\n",
    "    'conv_block' : 'unet',\n",
    "\n",
    "    # Loss function\n",
    "    'dice_gam': 1,\n",
    "    'th': 0.5,\n",
    "\n",
    "    # Visualizer\n",
    "    'display_interval': 100,\n",
    "\n",
    "    # Checkpoint\n",
    "    'save_interval': 5,\n",
    "}\n",
    "\n",
    "configs = Namespace(**args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a2cbc39-2028-455f-b9f5-8c39edc7c83f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adddcd47b8da47ddaa47a1952309c79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1987394f7045df98fe5735a7873a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Dataloader\n",
    "data_loader = heart_dataloader( root='train',\n",
    "                                batch_size=configs.batch_size,\n",
    "                                sift=configs.sift,\n",
    "                                test=False)\n",
    "    \n",
    "train_dataloader,validation_dataloader= data_loader.train_dl , data_loader.val_dl\n",
    "\n",
    "# check the loaded files paths\n",
    "# print(data_loader.images_paths)\n",
    "# print(data_loader.labels_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96074c77-e1a6-4547-a0cb-ddec97afd259",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b79c9864-0a7a-462d-8830-f4da7415f692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNET param count = 7786325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define some peripheral variables that are often used\n",
    "epoch = configs.epochs\n",
    "\n",
    "dice_gam = torch.tensor(configs.dice_gam, dtype=torch.float32, device=configs.device)\n",
    "\n",
    "\n",
    "# Input transforms including: (preprocessing, data augmentation)\n",
    "input_transform = PreprocessAug(device=configs.device, \n",
    "                                batch_size=configs.batch_size,\n",
    "                                crop_size=configs.crop_size)\n",
    "\n",
    "\n",
    "# Define U-Net\n",
    "model = variable_unet_class(in_channels=1,\n",
    "                            out_channels=1,\n",
    "                            init_filters=configs.init_filters,\n",
    "                            block_count=configs.block_count,\n",
    "                            upsample=configs.upsample,\n",
    "                            conv_block=configs.conv_block)\n",
    "\n",
    "\n",
    "# Define loss\n",
    "\n",
    "def dice_coeff(input, label):\n",
    "    smooth = 1.\n",
    "    iflat = input.contiguous().view(-1)\n",
    "    lflat = label.contiguous().view(-1)\n",
    "    intersection = (iflat * lflat).sum()\n",
    "    \n",
    "    return ((2. * intersection + smooth) / (iflat.sum() + lflat.sum() + smooth))\n",
    "\n",
    "class dice_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        dice_val = dice_coeff(input, label)\n",
    "        return 1 - dice_val\n",
    "\n",
    "BCE_LOSS = nn.BCEWithLogitsLoss()\n",
    "DICE_LOSS = dice_loss()\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "# Define optimizers\n",
    "optimizer = optim.Adam(model.parameters(), lr=configs.lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, cooldown=1, min_lr=1e-8, eps=1e-08, verbose=True)\n",
    "\n",
    "# Visualizer\n",
    "writer = SummaryWriter(str(configs.log_root))\n",
    "\n",
    "count_params = lambda x : sum(p.numel() for p in x.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = count_params(model)\n",
    "\n",
    "print(f'UNET param count = {total_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e87a25-8f47-4165-bc13-fc65a7577da6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a8711b7-9873-46df-b4af-e510e0900ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define forward pass used for both training/validation\n",
    "def forward_pass( input : torch.Tensor, \n",
    "                  label : torch.Tensor, \n",
    "                  model : torch.nn.Module,\n",
    "                  dice_gam):\n",
    "    \n",
    "    # forward pass\n",
    "    output = model(input).float()\n",
    "\n",
    "    # calculate loss\n",
    "    step_bceloss = BCE_LOSS(output, label)\n",
    "    step_diceloss = DICE_LOSS(output,label)\n",
    "    step_loss = step_bceloss\n",
    "    step_metric = step_diceloss\n",
    "\n",
    "    return output, step_loss, step_metric\n",
    "\n",
    "def normalize_im(tensor: torch.Tensor)->torch.Tensor:\n",
    "    \n",
    "    large = torch.max(tensor).cpu().data\n",
    "    small = torch.min(tensor).cpu().data\n",
    "    diff = large - small\n",
    "    \n",
    "    normalized_tensor = (tensor.clamp(min=small, max=large) - small) * (torch.tensor(1) / diff)\n",
    "    \n",
    "    return normalized_tensor\n",
    "\n",
    "def postprocess_im(tensor: torch.Tensor ,th: float = 0.5):\n",
    "    \"\"\"\n",
    "    1. Applies sigmoid layer to U-Net output\n",
    "    2. Thresholds to certain value. \n",
    "    i.e.) Values lower than th = 0 / Values higher than th = 1\n",
    "    \"\"\"\n",
    "    \n",
    "    tensor_th = tensor.clone()\n",
    "    tensor_th = sigmoid(tensor_th)\n",
    "    tensor_th[tensor_th <= th] = 0\n",
    "    tensor_th[tensor_th > th] = 1\n",
    "    \n",
    "    return tensor_th\n",
    "\n",
    "\n",
    "# logger\n",
    "def log_epoch(epoch, epoch_loss, epoch_metrics, writer, elapsed_secs,lr ,training=True):\n",
    "    \n",
    "    mode = 'Training' if training else 'Validation'\n",
    "    \n",
    "    string = \\\n",
    "    f'''Epoch {epoch:03d} {mode}.\\tloss: {epoch_loss[i-1]:.4e}.\\tTime: {elapsed_secs // 60} min {elapsed_secs % 60} sec\\tDice={epoch_metrics:.4e}\\tLR ={lr:.3e}'''\n",
    "    \n",
    "    print(string)\n",
    "\n",
    "# metric calculator\n",
    "def get_step_metric(output, label):\n",
    "    \n",
    "    dice = dice_coeff(output, label)   \n",
    "    \n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cdacceaf-a739-4a1f-b577-fa64376ab2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 Training.\tloss: 1.9369e+01.\tTime: 0 min 2 sec\tDice=1.4482e-03\tLR =1.000e-02\n",
      "Epoch 001 Validation.\tloss: 8.4777e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 002 Training.\tloss: 3.3675e+00.\tTime: 0 min 2 sec\tDice=9.0189e-05\tLR =1.000e-02\n",
      "Epoch 002 Validation.\tloss: 4.5858e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 003 Training.\tloss: 2.0448e+00.\tTime: 0 min 2 sec\tDice=8.9422e-05\tLR =1.000e-02\n",
      "Epoch 003 Validation.\tloss: 2.9949e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 004 Training.\tloss: 1.6939e+00.\tTime: 0 min 2 sec\tDice=9.0327e-05\tLR =1.000e-02\n",
      "Epoch 004 Validation.\tloss: 4.4753e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 005 Training.\tloss: 1.4442e+00.\tTime: 0 min 2 sec\tDice=8.9975e-05\tLR =1.000e-02\n",
      "Epoch 005 Validation.\tloss: 3.8847e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 006 Training.\tloss: 1.3586e+00.\tTime: 0 min 2 sec\tDice=8.9725e-05\tLR =1.000e-02\n",
      "Epoch 006 Validation.\tloss: 2.4652e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 007 Training.\tloss: 1.2294e+00.\tTime: 0 min 2 sec\tDice=9.0001e-05\tLR =1.000e-02\n",
      "Epoch 007 Validation.\tloss: 1.9308e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 008 Training.\tloss: 1.2002e+00.\tTime: 0 min 2 sec\tDice=9.0051e-05\tLR =1.000e-02\n",
      "Epoch 008 Validation.\tloss: 2.1716e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 009 Training.\tloss: 1.1459e+00.\tTime: 0 min 2 sec\tDice=8.9827e-05\tLR =1.000e-02\n",
      "Epoch 009 Validation.\tloss: 2.4031e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 010 Training.\tloss: 1.1501e+00.\tTime: 0 min 2 sec\tDice=9.0587e-05\tLR =1.000e-02\n",
      "Epoch 010 Validation.\tloss: 1.7466e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 011 Training.\tloss: 1.0710e+00.\tTime: 0 min 2 sec\tDice=8.9704e-05\tLR =1.000e-02\n",
      "Epoch 011 Validation.\tloss: 1.8868e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 012 Training.\tloss: 1.0496e+00.\tTime: 0 min 2 sec\tDice=8.9891e-05\tLR =1.000e-02\n",
      "Epoch 012 Validation.\tloss: 3.5761e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 013 Training.\tloss: 1.0113e+00.\tTime: 0 min 2 sec\tDice=8.9043e-05\tLR =1.000e-02\n",
      "Epoch 013 Validation.\tloss: 1.6254e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 014 Training.\tloss: 1.0113e+00.\tTime: 0 min 2 sec\tDice=9.0037e-05\tLR =1.000e-02\n",
      "Epoch 014 Validation.\tloss: 1.8725e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 015 Training.\tloss: 9.6324e-01.\tTime: 0 min 2 sec\tDice=9.0117e-05\tLR =1.000e-02\n",
      "Epoch 015 Validation.\tloss: 1.6958e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 016 Training.\tloss: 9.1397e-01.\tTime: 0 min 2 sec\tDice=8.9376e-05\tLR =1.000e-02\n",
      "Epoch 016 Validation.\tloss: 2.1912e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 017 Training.\tloss: 8.7532e-01.\tTime: 0 min 2 sec\tDice=9.0226e-05\tLR =1.000e-02\n",
      "Epoch 017 Validation.\tloss: 2.8201e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 018 Training.\tloss: 8.5752e-01.\tTime: 0 min 2 sec\tDice=8.9384e-05\tLR =1.000e-02\n",
      "Epoch 018 Validation.\tloss: 2.8718e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =1.000e-02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch    19: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch 019 Training.\tloss: 8.1855e-01.\tTime: 0 min 2 sec\tDice=9.0180e-05\tLR =5.000e-03\n",
      "Epoch 019 Validation.\tloss: 1.6491e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 020 Training.\tloss: 7.8705e-01.\tTime: 0 min 2 sec\tDice=8.9895e-05\tLR =5.000e-03\n",
      "Epoch 020 Validation.\tloss: 1.2876e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 021 Training.\tloss: 7.6383e-01.\tTime: 0 min 2 sec\tDice=8.9488e-05\tLR =5.000e-03\n",
      "Epoch 021 Validation.\tloss: 1.3013e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 022 Training.\tloss: 7.3949e-01.\tTime: 0 min 2 sec\tDice=8.9825e-05\tLR =5.000e-03\n",
      "Epoch 022 Validation.\tloss: 1.5911e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 023 Training.\tloss: 7.3374e-01.\tTime: 0 min 2 sec\tDice=9.1271e-05\tLR =5.000e-03\n",
      "Epoch 023 Validation.\tloss: 1.3529e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 024 Training.\tloss: 7.2060e-01.\tTime: 0 min 2 sec\tDice=8.9433e-05\tLR =5.000e-03\n",
      "Epoch 024 Validation.\tloss: 1.3936e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 025 Training.\tloss: 7.1517e-01.\tTime: 0 min 2 sec\tDice=9.0201e-05\tLR =5.000e-03\n",
      "Epoch 025 Validation.\tloss: 1.2045e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 026 Training.\tloss: 7.1093e-01.\tTime: 0 min 2 sec\tDice=8.9766e-05\tLR =5.000e-03\n",
      "Epoch 026 Validation.\tloss: 1.1193e-01.\tTime: 0 min 0 sec\tDice=9.1696e-05\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 027 Training.\tloss: 6.9111e-01.\tTime: 0 min 2 sec\tDice=5.2533e-01\tLR =5.000e-03\n",
      "Epoch 027 Validation.\tloss: 1.1370e-01.\tTime: 0 min 0 sec\tDice=7.9383e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 028 Training.\tloss: 6.6099e-01.\tTime: 0 min 2 sec\tDice=8.2921e-01\tLR =5.000e-03\n",
      "Epoch 028 Validation.\tloss: 1.1592e-01.\tTime: 0 min 0 sec\tDice=7.7387e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 029 Training.\tloss: 6.5888e-01.\tTime: 0 min 2 sec\tDice=8.2966e-01\tLR =5.000e-03\n",
      "Epoch 029 Validation.\tloss: 2.0020e-01.\tTime: 0 min 0 sec\tDice=5.3229e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 030 Training.\tloss: 6.6254e-01.\tTime: 0 min 2 sec\tDice=8.2435e-01\tLR =5.000e-03\n",
      "Epoch 030 Validation.\tloss: 1.7485e-01.\tTime: 0 min 0 sec\tDice=5.1370e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 031 Training.\tloss: 6.4223e-01.\tTime: 0 min 2 sec\tDice=8.3135e-01\tLR =5.000e-03\n",
      "Epoch 031 Validation.\tloss: 1.1059e-01.\tTime: 0 min 0 sec\tDice=7.6311e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 032 Training.\tloss: 6.4729e-01.\tTime: 0 min 2 sec\tDice=8.2677e-01\tLR =5.000e-03\n",
      "Epoch 032 Validation.\tloss: 1.2692e-01.\tTime: 0 min 0 sec\tDice=7.5253e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 033 Training.\tloss: 6.1359e-01.\tTime: 0 min 2 sec\tDice=8.4713e-01\tLR =5.000e-03\n",
      "Epoch 033 Validation.\tloss: 1.0230e-01.\tTime: 0 min 0 sec\tDice=7.9995e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 034 Training.\tloss: 6.0816e-01.\tTime: 0 min 2 sec\tDice=8.4243e-01\tLR =5.000e-03\n",
      "Epoch 034 Validation.\tloss: 1.9358e-01.\tTime: 0 min 0 sec\tDice=6.2549e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 035 Training.\tloss: 6.0938e-01.\tTime: 0 min 2 sec\tDice=8.3881e-01\tLR =5.000e-03\n",
      "Epoch 035 Validation.\tloss: 1.3866e-01.\tTime: 0 min 0 sec\tDice=6.8987e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 036 Training.\tloss: 6.0523e-01.\tTime: 0 min 2 sec\tDice=8.3998e-01\tLR =5.000e-03\n",
      "Epoch 036 Validation.\tloss: 9.9978e-02.\tTime: 0 min 0 sec\tDice=8.2349e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 037 Training.\tloss: 5.9077e-01.\tTime: 0 min 2 sec\tDice=8.4652e-01\tLR =5.000e-03\n",
      "Epoch 037 Validation.\tloss: 1.1640e-01.\tTime: 0 min 0 sec\tDice=7.7401e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 038 Training.\tloss: 5.7437e-01.\tTime: 0 min 2 sec\tDice=8.5173e-01\tLR =5.000e-03\n",
      "Epoch 038 Validation.\tloss: 9.4080e-02.\tTime: 0 min 0 sec\tDice=8.3604e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 039 Training.\tloss: 5.8529e-01.\tTime: 0 min 2 sec\tDice=8.4654e-01\tLR =5.000e-03\n",
      "Epoch 039 Validation.\tloss: 9.6056e-02.\tTime: 0 min 0 sec\tDice=8.2261e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 040 Training.\tloss: 5.5345e-01.\tTime: 0 min 2 sec\tDice=8.5893e-01\tLR =5.000e-03\n",
      "Epoch 040 Validation.\tloss: 1.3194e-01.\tTime: 0 min 0 sec\tDice=7.1701e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 041 Training.\tloss: 5.5985e-01.\tTime: 0 min 2 sec\tDice=8.5337e-01\tLR =5.000e-03\n",
      "Epoch 041 Validation.\tloss: 2.0634e-01.\tTime: 0 min 0 sec\tDice=3.4796e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 042 Training.\tloss: 5.3931e-01.\tTime: 0 min 2 sec\tDice=8.6316e-01\tLR =5.000e-03\n",
      "Epoch 042 Validation.\tloss: 1.0123e-01.\tTime: 0 min 0 sec\tDice=7.7243e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 043 Training.\tloss: 5.1953e-01.\tTime: 0 min 2 sec\tDice=8.7045e-01\tLR =5.000e-03\n",
      "Epoch 043 Validation.\tloss: 9.3109e-02.\tTime: 0 min 0 sec\tDice=8.3341e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 044 Training.\tloss: 5.3050e-01.\tTime: 0 min 2 sec\tDice=8.6179e-01\tLR =5.000e-03\n",
      "Epoch 044 Validation.\tloss: 2.0109e-01.\tTime: 0 min 0 sec\tDice=4.0630e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 045 Training.\tloss: 5.2335e-01.\tTime: 0 min 2 sec\tDice=8.6450e-01\tLR =5.000e-03\n",
      "Epoch 045 Validation.\tloss: 9.8979e-02.\tTime: 0 min 0 sec\tDice=8.0838e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 046 Training.\tloss: 4.9471e-01.\tTime: 0 min 2 sec\tDice=8.7391e-01\tLR =5.000e-03\n",
      "Epoch 046 Validation.\tloss: 9.0498e-02.\tTime: 0 min 0 sec\tDice=8.1383e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 047 Training.\tloss: 4.9079e-01.\tTime: 0 min 2 sec\tDice=8.7661e-01\tLR =5.000e-03\n",
      "Epoch 047 Validation.\tloss: 8.8312e-02.\tTime: 0 min 0 sec\tDice=8.3660e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 048 Training.\tloss: 4.8847e-01.\tTime: 0 min 2 sec\tDice=8.7672e-01\tLR =5.000e-03\n",
      "Epoch 048 Validation.\tloss: 1.0039e-01.\tTime: 0 min 0 sec\tDice=8.2474e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 049 Training.\tloss: 4.8215e-01.\tTime: 0 min 2 sec\tDice=8.7561e-01\tLR =5.000e-03\n",
      "Epoch 049 Validation.\tloss: 9.6117e-02.\tTime: 0 min 0 sec\tDice=7.8509e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 050 Training.\tloss: 4.6096e-01.\tTime: 0 min 2 sec\tDice=8.8310e-01\tLR =5.000e-03\n",
      "Epoch 050 Validation.\tloss: 7.8123e-02.\tTime: 0 min 0 sec\tDice=8.5490e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 051 Training.\tloss: 4.6990e-01.\tTime: 0 min 2 sec\tDice=8.7507e-01\tLR =5.000e-03\n",
      "Epoch 051 Validation.\tloss: 8.6276e-02.\tTime: 0 min 0 sec\tDice=8.2054e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 052 Training.\tloss: 4.5869e-01.\tTime: 0 min 2 sec\tDice=8.8023e-01\tLR =5.000e-03\n",
      "Epoch 052 Validation.\tloss: 8.1150e-02.\tTime: 0 min 0 sec\tDice=8.4036e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 053 Training.\tloss: 4.5046e-01.\tTime: 0 min 2 sec\tDice=8.8259e-01\tLR =5.000e-03\n",
      "Epoch 053 Validation.\tloss: 8.7587e-02.\tTime: 0 min 0 sec\tDice=8.3742e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 054 Training.\tloss: 4.5404e-01.\tTime: 0 min 2 sec\tDice=8.7847e-01\tLR =5.000e-03\n",
      "Epoch 054 Validation.\tloss: 7.7911e-02.\tTime: 0 min 0 sec\tDice=8.4809e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 055 Training.\tloss: 4.4742e-01.\tTime: 0 min 2 sec\tDice=8.8164e-01\tLR =5.000e-03\n",
      "Epoch 055 Validation.\tloss: 9.7300e-02.\tTime: 0 min 0 sec\tDice=8.0704e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 056 Training.\tloss: 4.6290e-01.\tTime: 0 min 2 sec\tDice=8.7296e-01\tLR =5.000e-03\n",
      "Epoch 056 Validation.\tloss: 1.3402e-01.\tTime: 0 min 0 sec\tDice=6.7952e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 057 Training.\tloss: 4.2951e-01.\tTime: 0 min 2 sec\tDice=8.8585e-01\tLR =5.000e-03\n",
      "Epoch 057 Validation.\tloss: 7.9858e-02.\tTime: 0 min 0 sec\tDice=8.5388e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 058 Training.\tloss: 4.1434e-01.\tTime: 0 min 2 sec\tDice=8.9109e-01\tLR =5.000e-03\n",
      "Epoch 058 Validation.\tloss: 7.0286e-02.\tTime: 0 min 0 sec\tDice=8.7204e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 059 Training.\tloss: 4.0150e-01.\tTime: 0 min 2 sec\tDice=8.9483e-01\tLR =5.000e-03\n",
      "Epoch 059 Validation.\tloss: 7.1961e-02.\tTime: 0 min 0 sec\tDice=8.7148e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 060 Training.\tloss: 4.1079e-01.\tTime: 0 min 2 sec\tDice=8.8917e-01\tLR =5.000e-03\n",
      "Epoch 060 Validation.\tloss: 7.8842e-02.\tTime: 0 min 0 sec\tDice=8.4065e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 061 Training.\tloss: 4.1374e-01.\tTime: 0 min 2 sec\tDice=8.8799e-01\tLR =5.000e-03\n",
      "Epoch 061 Validation.\tloss: 6.9874e-02.\tTime: 0 min 0 sec\tDice=8.6756e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 062 Training.\tloss: 3.9902e-01.\tTime: 0 min 2 sec\tDice=8.8809e-01\tLR =5.000e-03\n",
      "Epoch 062 Validation.\tloss: 6.0878e-02.\tTime: 0 min 0 sec\tDice=8.9115e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 063 Training.\tloss: 3.9464e-01.\tTime: 0 min 2 sec\tDice=8.9173e-01\tLR =5.000e-03\n",
      "Epoch 063 Validation.\tloss: 6.2408e-02.\tTime: 0 min 0 sec\tDice=8.8874e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 064 Training.\tloss: 3.7789e-01.\tTime: 0 min 2 sec\tDice=8.9700e-01\tLR =5.000e-03\n",
      "Epoch 064 Validation.\tloss: 6.7643e-02.\tTime: 0 min 0 sec\tDice=8.6853e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 065 Training.\tloss: 3.7683e-01.\tTime: 0 min 2 sec\tDice=8.9629e-01\tLR =5.000e-03\n",
      "Epoch 065 Validation.\tloss: 7.0393e-02.\tTime: 0 min 0 sec\tDice=8.6947e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 066 Training.\tloss: 3.7725e-01.\tTime: 0 min 2 sec\tDice=8.9450e-01\tLR =5.000e-03\n",
      "Epoch 066 Validation.\tloss: 7.3187e-02.\tTime: 0 min 0 sec\tDice=8.6484e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 067 Training.\tloss: 3.7145e-01.\tTime: 0 min 2 sec\tDice=8.9524e-01\tLR =5.000e-03\n",
      "Epoch 067 Validation.\tloss: 8.2243e-02.\tTime: 0 min 0 sec\tDice=8.2386e-01\tLR =5.000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch    68: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch 068 Training.\tloss: 3.7737e-01.\tTime: 0 min 2 sec\tDice=8.9358e-01\tLR =2.500e-03\n",
      "Epoch 068 Validation.\tloss: 8.0711e-02.\tTime: 0 min 0 sec\tDice=8.3568e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 069 Training.\tloss: 3.6288e-01.\tTime: 0 min 2 sec\tDice=8.9619e-01\tLR =2.500e-03\n",
      "Epoch 069 Validation.\tloss: 6.5791e-02.\tTime: 0 min 0 sec\tDice=8.7634e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 070 Training.\tloss: 3.5492e-01.\tTime: 0 min 2 sec\tDice=9.0035e-01\tLR =2.500e-03\n",
      "Epoch 070 Validation.\tloss: 6.0859e-02.\tTime: 0 min 0 sec\tDice=8.8320e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 071 Training.\tloss: 3.3096e-01.\tTime: 0 min 2 sec\tDice=9.0980e-01\tLR =2.500e-03\n",
      "Epoch 071 Validation.\tloss: 6.3329e-02.\tTime: 0 min 0 sec\tDice=8.7364e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 072 Training.\tloss: 3.2715e-01.\tTime: 0 min 2 sec\tDice=9.0943e-01\tLR =2.500e-03\n",
      "Epoch 072 Validation.\tloss: 6.2158e-02.\tTime: 0 min 0 sec\tDice=8.7594e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 073 Training.\tloss: 3.2365e-01.\tTime: 0 min 2 sec\tDice=9.1121e-01\tLR =2.500e-03\n",
      "Epoch 073 Validation.\tloss: 6.2253e-02.\tTime: 0 min 0 sec\tDice=8.8229e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 074 Training.\tloss: 3.2459e-01.\tTime: 0 min 2 sec\tDice=9.0956e-01\tLR =2.500e-03\n",
      "Epoch 074 Validation.\tloss: 5.8165e-02.\tTime: 0 min 0 sec\tDice=8.9135e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 075 Training.\tloss: 3.2379e-01.\tTime: 0 min 2 sec\tDice=9.0869e-01\tLR =2.500e-03\n",
      "Epoch 075 Validation.\tloss: 5.6474e-02.\tTime: 0 min 0 sec\tDice=8.8842e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 076 Training.\tloss: 3.2352e-01.\tTime: 0 min 2 sec\tDice=9.0812e-01\tLR =2.500e-03\n",
      "Epoch 076 Validation.\tloss: 5.3901e-02.\tTime: 0 min 0 sec\tDice=9.0055e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 077 Training.\tloss: 3.2335e-01.\tTime: 0 min 2 sec\tDice=9.0910e-01\tLR =2.500e-03\n",
      "Epoch 077 Validation.\tloss: 6.0996e-02.\tTime: 0 min 0 sec\tDice=8.8275e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 078 Training.\tloss: 3.1609e-01.\tTime: 0 min 2 sec\tDice=9.1080e-01\tLR =2.500e-03\n",
      "Epoch 078 Validation.\tloss: 5.1400e-02.\tTime: 0 min 0 sec\tDice=9.0299e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 079 Training.\tloss: 3.2183e-01.\tTime: 0 min 2 sec\tDice=9.0741e-01\tLR =2.500e-03\n",
      "Epoch 079 Validation.\tloss: 9.5269e-02.\tTime: 0 min 0 sec\tDice=8.0800e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 080 Training.\tloss: 3.1685e-01.\tTime: 0 min 2 sec\tDice=9.1064e-01\tLR =2.500e-03\n",
      "Epoch 080 Validation.\tloss: 7.1629e-02.\tTime: 0 min 0 sec\tDice=8.5501e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 081 Training.\tloss: 3.0605e-01.\tTime: 0 min 2 sec\tDice=9.1237e-01\tLR =2.500e-03\n",
      "Epoch 081 Validation.\tloss: 5.4998e-02.\tTime: 0 min 0 sec\tDice=8.9443e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 082 Training.\tloss: 3.0788e-01.\tTime: 0 min 2 sec\tDice=9.1085e-01\tLR =2.500e-03\n",
      "Epoch 082 Validation.\tloss: 5.7182e-02.\tTime: 0 min 0 sec\tDice=8.8766e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 083 Training.\tloss: 3.1122e-01.\tTime: 0 min 2 sec\tDice=9.1040e-01\tLR =2.500e-03\n",
      "Epoch 083 Validation.\tloss: 5.9141e-02.\tTime: 0 min 0 sec\tDice=8.8087e-01\tLR =2.500e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch    84: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch 084 Training.\tloss: 3.1009e-01.\tTime: 0 min 2 sec\tDice=9.0841e-01\tLR =1.250e-03\n",
      "Epoch 084 Validation.\tloss: 5.2937e-02.\tTime: 0 min 0 sec\tDice=8.9642e-01\tLR =1.250e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 085 Training.\tloss: 3.0230e-01.\tTime: 0 min 2 sec\tDice=9.1180e-01\tLR =1.250e-03\n",
      "Epoch 085 Validation.\tloss: 6.2104e-02.\tTime: 0 min 0 sec\tDice=8.7686e-01\tLR =1.250e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 086 Training.\tloss: 2.9261e-01.\tTime: 0 min 2 sec\tDice=9.1644e-01\tLR =1.250e-03\n",
      "Epoch 086 Validation.\tloss: 5.7054e-02.\tTime: 0 min 0 sec\tDice=8.8671e-01\tLR =1.250e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 087 Training.\tloss: 2.8933e-01.\tTime: 0 min 2 sec\tDice=9.1709e-01\tLR =1.250e-03\n",
      "Epoch 087 Validation.\tloss: 6.4231e-02.\tTime: 0 min 0 sec\tDice=8.7110e-01\tLR =1.250e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 088 Training.\tloss: 2.9038e-01.\tTime: 0 min 2 sec\tDice=9.1624e-01\tLR =1.250e-03\n",
      "Epoch 088 Validation.\tloss: 6.3118e-02.\tTime: 0 min 0 sec\tDice=8.7038e-01\tLR =1.250e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 089 Training.\tloss: 2.8748e-01.\tTime: 0 min 2 sec\tDice=9.1688e-01\tLR =1.250e-03\n",
      "Epoch 089 Validation.\tloss: 6.1175e-02.\tTime: 0 min 0 sec\tDice=8.7567e-01\tLR =1.250e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 090 Training.\tloss: 2.8993e-01.\tTime: 0 min 2 sec\tDice=9.1563e-01\tLR =1.250e-03\n",
      "Epoch 090 Validation.\tloss: 5.5041e-02.\tTime: 0 min 0 sec\tDice=8.9337e-01\tLR =1.250e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch    91: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch 091 Training.\tloss: 2.8532e-01.\tTime: 0 min 2 sec\tDice=9.1682e-01\tLR =6.250e-04\n",
      "Epoch 091 Validation.\tloss: 6.3946e-02.\tTime: 0 min 0 sec\tDice=8.6800e-01\tLR =6.250e-04\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 092 Training.\tloss: 2.8069e-01.\tTime: 0 min 2 sec\tDice=9.1964e-01\tLR =6.250e-04\n",
      "Epoch 092 Validation.\tloss: 5.5503e-02.\tTime: 0 min 0 sec\tDice=8.8646e-01\tLR =6.250e-04\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 093 Training.\tloss: 2.8223e-01.\tTime: 0 min 2 sec\tDice=9.1826e-01\tLR =6.250e-04\n",
      "Epoch 093 Validation.\tloss: 6.3242e-02.\tTime: 0 min 0 sec\tDice=8.7221e-01\tLR =6.250e-04\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 094 Training.\tloss: 2.7990e-01.\tTime: 0 min 2 sec\tDice=9.1875e-01\tLR =6.250e-04\n",
      "Epoch 094 Validation.\tloss: 6.3194e-02.\tTime: 0 min 0 sec\tDice=8.7051e-01\tLR =6.250e-04\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 095 Training.\tloss: 2.7736e-01.\tTime: 0 min 2 sec\tDice=9.2039e-01\tLR =6.250e-04\n",
      "Epoch 095 Validation.\tloss: 5.9941e-02.\tTime: 0 min 0 sec\tDice=8.7800e-01\tLR =6.250e-04\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 096 Training.\tloss: 2.7760e-01.\tTime: 0 min 2 sec\tDice=9.1998e-01\tLR =6.250e-04\n",
      "Epoch 096 Validation.\tloss: 4.7644e-02.\tTime: 0 min 0 sec\tDice=9.0551e-01\tLR =6.250e-04\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 097 Training.\tloss: 2.7796e-01.\tTime: 0 min 2 sec\tDice=9.1972e-01\tLR =6.250e-04\n",
      "Epoch 097 Validation.\tloss: 5.3038e-02.\tTime: 0 min 0 sec\tDice=8.9421e-01\tLR =6.250e-04\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 098 Training.\tloss: 2.7539e-01.\tTime: 0 min 2 sec\tDice=9.2050e-01\tLR =6.250e-04\n",
      "Epoch 098 Validation.\tloss: 5.7107e-02.\tTime: 0 min 0 sec\tDice=8.8186e-01\tLR =6.250e-04\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 099 Training.\tloss: 2.7556e-01.\tTime: 0 min 2 sec\tDice=9.2030e-01\tLR =6.250e-04\n",
      "Epoch 099 Validation.\tloss: 4.8887e-02.\tTime: 0 min 0 sec\tDice=9.0414e-01\tLR =6.250e-04\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 100 Training.\tloss: 2.7514e-01.\tTime: 0 min 2 sec\tDice=9.2076e-01\tLR =6.250e-04\n",
      "Epoch 100 Validation.\tloss: 5.1994e-02.\tTime: 0 min 0 sec\tDice=8.9694e-01\tLR =6.250e-04\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses = list()\n",
    "val_losses = list()\n",
    "train_metric = list()\n",
    "val_metric = list()\n",
    "learning_rate = list()\n",
    "\n",
    "#move model to gpu\n",
    "if configs.device.startswith('cuda') :\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, epoch+1):\n",
    "    \n",
    "    '''\n",
    "     Training\n",
    "    '''\n",
    "    \n",
    "\n",
    "    epoch_train_loss    = list()\n",
    "    epoch_train_metrics = list()\n",
    "    tic_train = time()\n",
    "\n",
    "    model.train()\n",
    "    torch.autograd.set_grad_enabled(True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for step,(input, label) in enumerate(train_dataloader):\n",
    "        \n",
    "        print(f'epoch={i-1:003d}/{epoch:003d},\\tstep={step:003d}',end='\\r')\n",
    "        \n",
    "        input, label = input_transform(input.float(), label)\n",
    "        \n",
    "        # Flush gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        output, step_loss, step_metric = forward_pass(input, label, model, dice_gam)\n",
    "\n",
    "        # backward pass\n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Step metric, Aggregate to epoch_metrics\n",
    "        output_th = postprocess_im(output, th=configs.th)\n",
    "        step_metric = get_step_metric(output_th, label)\n",
    "\n",
    "        # Aggregate to epoch_loss and epoch metric\n",
    "        epoch_train_loss.append(step_loss.detach().cpu().numpy().astype('float32'))\n",
    "        epoch_train_metrics.append(step_metric.detach().cpu().numpy().astype('float32'))\n",
    "\n",
    "    \n",
    "    # log epoch\n",
    "    toc_train = int(time() - tic_train)\n",
    "    epoch_train_loss = sum(epoch_train_loss)\n",
    "    epoch_train_metrics = np.mean(epoch_train_metrics)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    train_metric.append(epoch_train_metrics)\n",
    "    \n",
    "\n",
    "    #-----------------------------------------------------------------------------#\n",
    "    \n",
    "    '''\n",
    "    Validation\n",
    "    '''\n",
    "    \n",
    "    epoch_val_loss    = list()\n",
    "    epoch_val_metrics = list()\n",
    "\n",
    "    tic_val = time()\n",
    "    model.eval()\n",
    "    torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "    for step,(input, label) in enumerate(validation_dataloader):\n",
    "        \n",
    "        print(f'epoch={i-1:003d}/{epoch:003d},\\tstep={step:003d}',end='\\r')  \n",
    "        \n",
    "        input, label = input_transform(input.float(), label, training=False)\n",
    "\n",
    "        # forward pass\n",
    "        output, step_loss, step_metric = forward_pass(input, label, model, dice_gam)\n",
    "        \n",
    "        \n",
    "        # Step metric, Aggregate to epoch_metrics\n",
    "        output_th = postprocess_im(output, th=configs.th)\n",
    "        step_metric = get_step_metric(output_th, label) \n",
    "        \n",
    "        # Aggregate to epoch_loss\n",
    "        epoch_val_loss.append(step_loss.detach().cpu().numpy().astype('float32'))\n",
    "        epoch_val_metrics.append(step_metric.detach().cpu().numpy().astype('float32'))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    # log epoch\n",
    "    toc_val = int(time() - tic_val)\n",
    "    epoch_val_loss = sum(epoch_val_loss)\n",
    "    epoch_val_metrics = np.mean(epoch_val_metrics)\n",
    "    \n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_metric.append(epoch_val_metrics)\n",
    "\n",
    "    scheduler.step(epoch_val_loss)\n",
    "    learning_rate.append(scheduler.state_dict()['_last_lr'][0])    \n",
    "    \n",
    "    # moving train logging here , since last lr is updated after validation step . otherwise it will throw an error\n",
    "    log_epoch(epoch          = i, \n",
    "          epoch_loss     = train_losses, \n",
    "          epoch_metrics  = epoch_train_metrics,\n",
    "          writer         = writer, \n",
    "          elapsed_secs   = toc_train, \n",
    "          lr             = learning_rate[-1],\n",
    "          training       = True\n",
    "         )\n",
    "    \n",
    "    log_epoch(epoch          = i, \n",
    "              epoch_loss     = val_losses, \n",
    "              epoch_metrics  = epoch_val_metrics,\n",
    "              writer         = writer, \n",
    "              elapsed_secs   = toc_val, \n",
    "              lr             = learning_rate[-1],\n",
    "              training       = False\n",
    "         )\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "    print('-'*100,)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64a6b7-03ad-4f84-957f-f13996ab12cc",
   "metadata": {},
   "source": [
    "#### save info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "16cb7483-e59f-4d02-8f7b-d259fecad82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = f'block_count_{configs.block_count}_params_{total_params}'\n",
    "\n",
    "save_path = os.path.join('models',name)\n",
    "\n",
    "#save model weights\n",
    "torch.save(model.state_dict(), f'{save_path}_model.tar')\n",
    "\n",
    "#save training history\n",
    "history = {\n",
    "            'train_loss':np.array(train_losses),\n",
    "            'val_loss': np.array(val_losses),\n",
    "            'train_metric':np.array(train_metric),\n",
    "            'val_metric':np.array(val_metric),\n",
    "            'lr':np.array(learning_rate)\n",
    "           }\n",
    "\n",
    "with open(f'{save_path}_history.pickle', 'wb') as file:\n",
    "    pickle.dump(history, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55918b30-789e-4abd-a814-b83c807d45e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd8921-8569-4818-b602-9d7d95e703fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get dice score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eefd058-9fc4-4db4-a4c4-9fbc23196b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dice_score = []\n",
    "\n",
    "# test_dataset = SegDataset(root='test',sift=False)\n",
    "\n",
    "# test_input_transform = PreprocessAug(device=0, batch_size=1,crop_size=320,full_size=320)\n",
    "# loaded_model = variable_unet_class(in_channels=1,out_channels=1,init_filters=64,upsample=False)\n",
    "# loaded_model.load_state_dict(torch.load('20_oct.tar'))\n",
    "# torch.autograd.set_grad_enabled(False)\n",
    "# loaded_model.eval()\n",
    "# loaded_model.cuda();\n",
    "\n",
    "\n",
    "# for test_image,test_label in test_dataset:\n",
    "    \n",
    "#     test_image_cuda,label_image_cuda = test_input_transform(test_image.float(),test_label.float(),training=False)\n",
    "    \n",
    "#     label_prediction = postprocess_im(loaded_model(test_image_cuda))\n",
    "\n",
    "#     dice_score.append(dice_coeff(label_prediction,label_image_cuda).detach().cpu().numpy())\n",
    "    \n",
    "# print(f'Tested samples\\t={len(dice_score)}\\ndice score\\t={np.mean(dice_score)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae15ce2-06f0-43f3-8415-9e0ec47394fe",
   "metadata": {},
   "source": [
    "#### Visualize test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f9ea6-8675-4c2f-8818-31d4620a34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import *\n",
    "# imshow_4dtensor = lambda tensor : plt.imshow(tensor[0,0].cpu().numpy())\n",
    "# test_dataset = SegDataset(root='test',sift=False)\n",
    "\n",
    "# test_input_transform = PreprocessAug(device=0, batch_size=1,crop_size=320,full_size=320)\n",
    "# loaded_model = variable_unet_class(in_channels=1,out_channels=1,init_filters=64,upsample=False)\n",
    "# loaded_model.load_state_dict(torch.load('20_oct.tar'))\n",
    "\n",
    "# loaded_model.cuda()\n",
    "\n",
    "# @interact(index = IntSlider(min=0,max=len(test_dataset)-1,continuous_update=False,))\n",
    "# def show_slice(index):\n",
    "\n",
    "#     plt.figure(figsize=(15,15))\n",
    "#     plt.subplot(1,3,1)\n",
    "#     plt.title('Input image')\n",
    "#     plt.imshow(test_dataset[index][0][0])\n",
    "#     plt.subplot(1,3,2)\n",
    "#     plt.title('True Mask')\n",
    "#     plt.imshow(test_dataset[index][1][0])\n",
    "#     plt.subplot(1,3,3)\n",
    "    \n",
    "#     plt.title('Predicted Mask')\n",
    "    \n",
    "#     test_image_cuda,label_image_cuda = test_input_transform(test_dataset[index][0].float(),test_dataset[index][1].float())\n",
    "    \n",
    "#     label_prediction = postprocess_im(loaded_model(test_image_cuda))\n",
    "    \n",
    "#     plt.imshow(label_prediction.detach().cpu().numpy()[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
